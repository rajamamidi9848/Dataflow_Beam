{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVvjudphEujAXWhK8nYX6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajamamidi9848/Dataflow_Beam/blob/main/Dataflow_Beam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S1STahiBA0aD",
        "outputId": "96d47942-8800-43aa-ac95-46c8b3ffb0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-beam[interactive]\n",
            "  Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam[interactive])\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam[interactive])\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam[interactive])\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam[interactive])\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam[interactive])\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[interactive])\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam[interactive])\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam[interactive])\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2024.1)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam[interactive])\n",
            "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2024.5.15)\n",
            "Collecting requests!=2.32.*,<3.0.0,>=2.24.0 (from apache-beam[interactive])\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam[interactive])\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam[interactive])\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Collecting facets-overview<2,>=1.1.0 (from apache-beam[interactive])\n",
            "  Downloading facets_overview-1.1.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-dataproc<6,>=5.0.0 (from apache-beam[interactive])\n",
            "  Downloading google_cloud_dataproc-5.10.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting ipython<9,>=8 (from apache-beam[interactive])\n",
            "  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting ipykernel<7,>=6 (from apache-beam[interactive])\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipywidgets<9,>=8 (from apache-beam[interactive])\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jupyter-client!=6.1.13,<8.2.1,>=6.1.11 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (6.1.12)\n",
            "Collecting timeloop<2,>=1.0.2 (from apache-beam[interactive])\n",
            "  Downloading timeloop-1.0.2.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nbformat<6,>=5.0.5 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (5.10.4)\n",
            "Requirement already satisfied: nbconvert<8,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (6.5.4)\n",
            "Requirement already satisfied: pandas!=1.5.0,!=1.5.1,<2.2,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.1.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (2.27.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.13.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[interactive])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[interactive]) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[interactive]) (3.1.4)\n",
            "Collecting comm>=0.1.1 (from ipykernel<7,>=6->apache-beam[interactive])\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.6.6)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython<9,>=8->apache-beam[interactive])\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (3.0.47)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (2.16.1)\n",
            "Collecting stack-data (from ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel<7,>=6->apache-beam[interactive])\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (1.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (4.9.0)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets<9,>=8->apache-beam[interactive])\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->apache-beam[interactive]) (3.0.13)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[interactive]) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam[interactive])\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (0.20.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (3.1.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat<6,>=5.0.5->apache-beam[interactive]) (2.20.0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,!=1.5.1,<2.2,>=1.4.3->apache-beam[interactive]) (2024.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam[interactive])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[interactive]) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (2024.7.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (1.65.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9,>=8->apache-beam[interactive]) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel<7,>=6->apache-beam[interactive]) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9,>=8->apache-beam[interactive]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9,>=8->apache-beam[interactive]) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert<8,>=6.2.0->apache-beam[interactive]) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.5.1)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pure-eval (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.6.0)\n",
            "Downloading facets_overview-1.1.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_dataproc-5.10.2-py2.py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.7/415.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.27.0-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: crcmod, dill, hdfs, timeloop, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31404 sha256=75628123f8de59a4bbdc964156ffb2b88d055d173600375de26194ec0a4c31dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=ca555bd02d4ed3a4a3abb2ef379e5bb31afb0aca3c4f9c32dda1fcf206aa118c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=797595c7aa1c4c107837aa635c6c0a4b3f2dced5215f8f3c6f068ebcf5f28dec\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for timeloop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeloop: filename=timeloop-1.0.2-py3-none-any.whl size=3703 sha256=e02780b797c58be246201c5396a8bed75188ebfe9866449ca37b4b43108f2a75\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/df/32/f72b9fd897c185cd70103331f70e4cb66e3df1de24bd476548\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=75faea46445d01fbc2e5f4ac02abac293f1516f671be9adebd38c26fdcfbb067\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=13c74bed6488fc293cfdf6169604d97cef25d5714f77afd1db10339f6f5467eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs timeloop pyjsparser docopt\n",
            "Installing collected packages: timeloop, pyjsparser, pure-eval, docopt, crcmod, zstandard, widgetsnbextension, traitlets, requests, redis, orjson, objsize, js2py, jedi, fasteners, fastavro, executing, dnspython, dill, asttokens, stack-data, pymongo, hdfs, comm, ipython, facets-overview, ipywidgets, ipykernel, apache-beam, google-cloud-dataproc\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.8\n",
            "    Uninstalling widgetsnbextension-3.6.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.8\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.27.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.58.1 asttokens-2.4.1 comm-0.2.2 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 executing-2.1.0 facets-overview-1.1.1 fastavro-1.9.5 fasteners-0.19 google-cloud-dataproc-5.10.2 hdfs-2.7.3 ipykernel-6.29.5 ipython-8.27.0 ipywidgets-8.1.5 jedi-0.19.1 js2py-0.74 objsize-0.7.0 orjson-3.10.7 pure-eval-0.2.3 pyjsparser-2.7.1 pymongo-4.8.0 redis-5.0.8 requests-2.31.0 stack-data-0.6.3 timeloop-1.0.2 traitlets-5.14.3 widgetsnbextension-4.0.13 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "google"
                ]
              },
              "id": "5739cf39d4ba445f8c9e5f9e16eac48d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install apache-beam[interactive]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Beam Program to read data from List and write that data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |beam.Create([\"hello\",\"world\",\"how\",\"are\",\"you\"])\n",
        "    |beam.io.WriteToCsv('/content/Data/Target/list')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "n5sjRP_pA-uD",
        "outputId": "7c76cfb0-7a40-4d59-f3b7-1ff6ccaa82bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc4258a7280>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/Data/Target/list-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfaIKZV6CL_O",
        "outputId": "21343524-6609-4099-884c-ad7e9f50ee9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "hello\n",
            "world\n",
            "how\n",
            "are\n",
            "you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from tuple and write data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |beam.Create((\"hello\",\"world\",\"Beams\",\"Dataflow\"))\n",
        "    |beam.io.WriteToCsv('/content/Data/Target/Tuple')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1kG2vXvETRt",
        "outputId": "d6b9a3ee-3b04-40b2-999d-12122bda7e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc424377f70>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/Data/Target/Tuple-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gue8qDpjE3jg",
        "outputId": "ffeaf36a-26e8-41d0-8f23-35e8b1cea55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "hello\n",
            "world\n",
            "Beams\n",
            "Dataflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |beam.Map(lambda record:record.split(','))\n",
        "    |beam.Filter(lambda record:record[8]=='US')\n",
        "    |beam.Map(lambda record:(record[7],1))\n",
        "    |beam.CombinePerKey(sum)\n",
        "    |beam.io.WriteToText('/content/Data/Target/employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF77I6r-Vk1Z",
        "outputId": "aab87637-177c-428d-c53d-c4517d92e5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc4243b7bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat \"/content/Data/Target/employee_processed-00000-of-00001\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myVJLh7DnI7H",
        "outputId": "93a82ff9-1064-411c-cd97-fce0851d8b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def Filter(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    #|beam.Map(lambda record:record.split(','))\n",
        "    |beam.Map(Split)\n",
        "    #|beam.Filter(lambda record:record[8]=='US')\n",
        "    |beam.Filter(Filter)\n",
        "    #|beam.Map(lambda record:(record[7],1))\n",
        "    |beam.Map(addingOne)\n",
        "    |beam.CombinePerKey(sum)\n",
        "    |beam.io.WriteToText('/content/Data/Target/employee_processed_1')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "XlwCQtC7RlcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8c2aa5-edfd-46c3-cf8c-d6f26510cf16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ce3a560>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Data/Target/beam-temp-employee_processed_1-f00a460c6abb11efbab00242ac1c000c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNWdX7GME_Za",
        "outputId": "19d2914f-76c3-4d53-d6cd-996aa1c5d565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /content/Data/Target/beam-temp-employee_processed_1-f00a460c6abb11efbab00242ac1c000c: Is a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat '/content/Data/Target/employee_processed_1-00000-of-00001'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0taWQVtwFavL",
        "outputId": "02813172-d3a4-40b8-9f88-5646ea5d2c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def Filter(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    #|beam.Map(lambda record:record.split(','))\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        "    #|beam.Filter(lambda record:record[8]=='US')\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|beam.Map(lambda record:(record[7],1))\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/employee_processed_2')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLsDmG_3Fmhw",
        "outputId": "90c1b902-2dfa-4b9a-d345-9484dfcce352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ce93be0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat '/content/Data/Target/employee_processed_2-00000-of-00001'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unEHJBO5H1kJ",
        "outputId": "155afc39-6474-4aca-eab6-444bc7fc7b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "US_Pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    p1\n",
        "    |'IN Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'IN Split based on comma' >> beam.Map(Split)\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpc9bXI0IE7J",
        "outputId": "dbcf7908-55eb-4d81-c337-2263e6a4e472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ee66e90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zct6OKCUJyRj",
        "outputId": "54f3e17a-50eb-480f-8c70-bd3fff59bd17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc428183d90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "#How to perform Branching by using multiple transformation[Flatten]\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "   #|'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    #|'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "Output=(\n",
        "    (US_Pcollection,IN_Pcollection)\n",
        "    |beam.Flatten()\n",
        "    |beam.io.WriteToText('/content/Data/Target/IN_US_Branch_employee_processed')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXROzlWyMroN",
        "outputId": "08d17d68-a19f-4ff7-f351-ec8c4dc9ebea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ec03310>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat '/content/Data/Target/IN_US_Branch_employee_processed-00000-of-00001'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJy2TUnBNkyR",
        "outputId": "7df48628-643d-4c91-8f5f-6ecc586e8f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n",
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "#How to perform Branching by using multiple transformation[Flatten]\n",
        "#combining\n",
        "import apache_beam as beam\n",
        "\n",
        "#Syntax for Composite Transformation\n",
        "class Transform(beam.PTransform):  #Transform name we can able to change\n",
        "  def expand(self,input_coll):  #input_coll we can change\n",
        "    coll=(   #coll we can change\n",
        "        input_coll\n",
        "        |'Adding one for each column' >> beam.Map(lambda record:(record[7],1))\n",
        "        |'Grouping and summing operations' >> beam.CombinePerKey(sum)\n",
        "    )\n",
        "    return coll\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|'appending one for each department id' >> beam.Map(addingOne)\n",
        "    #|'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Composite Transformation1' >> Transform()\n",
        "   #|'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    #|'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Composite Transformation2' >> Transform()\n",
        "    #|'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "Output=(\n",
        "    (US_Pcollection,IN_Pcollection)\n",
        "    |beam.Flatten()\n",
        "    |beam.io.WriteToText('/content/Data/Target/IN_US_Composite_Branch_employee_processed')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyoIqb7nQAFd",
        "outputId": "40c2a747-82ac-479e-f764-d5fa7ade7a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41eeaafb0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat '/content/Data/Target/IN_US_Composite_Branch_employee_processed-00000-of-00001'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ZRRFY4VTA2",
        "outputId": "8f7fc5ec-4442-4b43-ee96-652ef06f62de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n",
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ]
    }
  ]
}