{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajamamidi9848/Dataflow_Beam/blob/main/Dataflow_Beam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S1STahiBA0aD",
        "outputId": "e323e17b-e17b-4246-c26f-7e5dc9648d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting apache-beam[interactive]\n",
            "  Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam[interactive])\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam[interactive])\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam[interactive])\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam[interactive])\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam[interactive])\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[interactive])\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (3.2.2)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam[interactive])\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam[interactive])\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2024.1)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam[interactive])\n",
            "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2024.5.15)\n",
            "Collecting requests!=2.32.*,<3.0.0,>=2.24.0 (from apache-beam[interactive])\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam[interactive])\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam[interactive])\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Collecting facets-overview<2,>=1.1.0 (from apache-beam[interactive])\n",
            "  Downloading facets_overview-1.1.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-dataproc<6,>=5.0.0 (from apache-beam[interactive])\n",
            "  Downloading google_cloud_dataproc-5.11.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting ipython<9,>=8 (from apache-beam[interactive])\n",
            "  Downloading ipython-8.27.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting ipykernel<7,>=6 (from apache-beam[interactive])\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipywidgets<9,>=8 (from apache-beam[interactive])\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jupyter-client!=6.1.13,<8.2.1,>=6.1.11 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (6.1.12)\n",
            "Collecting timeloop<2,>=1.0.2 (from apache-beam[interactive])\n",
            "  Downloading timeloop-1.0.2.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nbformat<6,>=5.0.5 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (5.10.4)\n",
            "Requirement already satisfied: nbconvert<8,>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (6.5.4)\n",
            "Requirement already satisfied: pandas!=1.5.0,!=1.5.1,<2.2,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam[interactive]) (2.1.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (2.19.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (2.27.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.13.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[interactive])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[interactive]) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam[interactive]) (3.1.4)\n",
            "Collecting comm>=0.1.1 (from ipykernel<7,>=6->apache-beam[interactive])\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.6.6)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (6.3.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel<7,>=6->apache-beam[interactive]) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython<9,>=8->apache-beam[interactive])\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (3.0.47)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (2.16.1)\n",
            "Collecting stack-data (from ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel<7,>=6->apache-beam[interactive])\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (1.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9,>=8->apache-beam[interactive]) (4.9.0)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets<9,>=8->apache-beam[interactive])\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->apache-beam[interactive]) (3.0.13)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam[interactive]) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam[interactive])\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[interactive]) (0.20.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (3.1.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert<8,>=6.2.0->apache-beam[interactive]) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat<6,>=5.0.5->apache-beam[interactive]) (2.20.0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.5.0,!=1.5.1,<2.2,>=1.4.3->apache-beam[interactive]) (2024.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam[interactive])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam[interactive]) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam[interactive]) (2024.8.30)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (1.65.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9,>=8->apache-beam[interactive]) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel<7,>=6->apache-beam[interactive]) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9,>=8->apache-beam[interactive]) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9,>=8->apache-beam[interactive]) (0.2.13)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert<8,>=6.2.0->apache-beam[interactive]) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert<8,>=6.2.0->apache-beam[interactive]) (0.5.1)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pure-eval (from stack-data->ipython<9,>=8->apache-beam[interactive])\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-dataproc<6,>=5.0.0->apache-beam[interactive]) (0.6.0)\n",
            "Downloading facets_overview-1.1.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_dataproc-5.11.0-py2.py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.7/415.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.27.0-py3-none-any.whl (818 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: crcmod, dill, hdfs, timeloop, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=d86dcdac167f4c3914765a2cd45d3b1402ae4d136d025dc3bfad4da00c0108c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=ab35689374e120fc237a8d289c1d6f73834b1aa2769ea12948517c4770994ecb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=72a0bd7ab17dacc8faae2fff95198b2abe0b6220da0e75a025ea82a49c46da29\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for timeloop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeloop: filename=timeloop-1.0.2-py3-none-any.whl size=3703 sha256=85817ae62ee68e92851a97bc850c741ce8be13c4d7d9b17079bd653cdb7725c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/df/32/f72b9fd897c185cd70103331f70e4cb66e3df1de24bd476548\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=a361b9ab97276f29a558e5046d62a1d6c675eb061aa70e07da285ce83516e142\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=dd7874b7b90946a16b6783a4434de51aed0fbdab297935a920fb24a2cd4b7e66\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs timeloop pyjsparser docopt\n",
            "Installing collected packages: timeloop, pyjsparser, pure-eval, docopt, crcmod, zstandard, widgetsnbextension, traitlets, requests, redis, orjson, objsize, js2py, jedi, fasteners, fastavro, executing, dnspython, dill, asttokens, stack-data, pymongo, hdfs, comm, ipython, facets-overview, ipywidgets, ipykernel, apache-beam, google-cloud-dataproc\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.8\n",
            "    Uninstalling widgetsnbextension-3.6.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.8\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.27.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.58.1 asttokens-2.4.1 comm-0.2.2 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 executing-2.1.0 facets-overview-1.1.1 fastavro-1.9.7 fasteners-0.19 google-cloud-dataproc-5.11.0 hdfs-2.7.3 ipykernel-6.29.5 ipython-8.27.0 ipywidgets-8.1.5 jedi-0.19.1 js2py-0.74 objsize-0.7.0 orjson-3.10.7 pure-eval-0.2.3 pyjsparser-2.7.1 pymongo-4.8.0 redis-5.0.8 requests-2.31.0 stack-data-0.6.3 timeloop-1.0.2 traitlets-5.14.3 widgetsnbextension-4.0.13 zstandard-0.23.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "39ea3894f2fe4341b6fb617667d9a3ab",
              "pip_warning": {
                "packages": [
                  "IPython",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install apache-beam[interactive]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "n5sjRP_pA-uD",
        "outputId": "7c76cfb0-7a40-4d59-f3b7-1ff6ccaa82bc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc4258a7280>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Beam Program to read data from List and write that data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |beam.Create([\"hello\",\"world\",\"how\",\"are\",\"you\"])\n",
        "    |beam.io.WriteToCsv('/content/Data/Target/list')\n",
        ")\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfaIKZV6CL_O",
        "outputId": "21343524-6609-4099-884c-ad7e9f50ee9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "hello\n",
            "world\n",
            "how\n",
            "are\n",
            "you\n"
          ]
        }
      ],
      "source": [
        "!cat \"/content/Data/Target/list-00000-of-00001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1kG2vXvETRt",
        "outputId": "d6b9a3ee-3b04-40b2-999d-12122bda7e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc424377f70>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read data from tuple and write data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |beam.Create((\"hello\",\"world\",\"Beams\",\"Dataflow\"))\n",
        "    |beam.io.WriteToCsv('/content/Data/Target/Tuple')\n",
        ")\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gue8qDpjE3jg",
        "outputId": "ffeaf36a-26e8-41d0-8f23-35e8b1cea55f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "hello\n",
            "world\n",
            "Beams\n",
            "Dataflow\n"
          ]
        }
      ],
      "source": [
        "!cat \"/content/Data/Target/Tuple-00000-of-00001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF77I6r-Vk1Z",
        "outputId": "aab87637-177c-428d-c53d-c4517d92e5e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc4243b7bb0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |beam.Map(lambda record:record.split(','))\n",
        "    |beam.Filter(lambda record:record[8]=='US')\n",
        "    |beam.Map(lambda record:(record[7],1))\n",
        "    |beam.CombinePerKey(sum)\n",
        "    |beam.io.WriteToText('/content/Data/Target/employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myVJLh7DnI7H",
        "outputId": "93a82ff9-1064-411c-cd97-fce0851d8b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ],
      "source": [
        "!cat \"/content/Data/Target/employee_processed-00000-of-00001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlwCQtC7RlcP",
        "outputId": "be8c2aa5-edfd-46c3-cf8c-d6f26510cf16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ce3a560>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def Filter(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    #|beam.Map(lambda record:record.split(','))\n",
        "    |beam.Map(Split)\n",
        "    #|beam.Filter(lambda record:record[8]=='US')\n",
        "    |beam.Filter(Filter)\n",
        "    #|beam.Map(lambda record:(record[7],1))\n",
        "    |beam.Map(addingOne)\n",
        "    |beam.CombinePerKey(sum)\n",
        "    |beam.io.WriteToText('/content/Data/Target/employee_processed_1')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNWdX7GME_Za",
        "outputId": "19d2914f-76c3-4d53-d6cd-996aa1c5d565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat: /content/Data/Target/beam-temp-employee_processed_1-f00a460c6abb11efbab00242ac1c000c: Is a directory\n"
          ]
        }
      ],
      "source": [
        "!cat /content/Data/Target/beam-temp-employee_processed_1-f00a460c6abb11efbab00242ac1c000c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0taWQVtwFavL",
        "outputId": "02813172-d3a4-40b8-9f88-5646ea5d2c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/Target/employee_processed_1-00000-of-00001'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLsDmG_3Fmhw",
        "outputId": "90c1b902-2dfa-4b9a-d345-9484dfcce352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ce93be0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def Filter(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines2=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    #|beam.Map(lambda record:record.split(','))\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        "    #|beam.Filter(lambda record:record[8]=='US')\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|beam.Map(lambda record:(record[7],1))\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/employee_processed_2')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unEHJBO5H1kJ",
        "outputId": "155afc39-6474-4aca-eab6-444bc7fc7b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/Target/employee_processed_2-00000-of-00001'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpc9bXI0IE7J",
        "outputId": "dbcf7908-55eb-4d81-c337-2263e6a4e472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ee66e90>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "US_Pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    p1\n",
        "    |'IN Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'IN Split based on comma' >> beam.Map(Split)\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zct6OKCUJyRj",
        "outputId": "54f3e17a-50eb-480f-8c70-bd3fff59bd17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc428183d90>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXROzlWyMroN",
        "outputId": "08d17d68-a19f-4ff7-f351-ec8c4dc9ebea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41ec03310>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "#How to perform Branching by using multiple transformation[Flatten]\n",
        "import apache_beam as beam\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "   #|'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    |'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    |'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    #|'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "Output=(\n",
        "    (US_Pcollection,IN_Pcollection)\n",
        "    |beam.Flatten()\n",
        "    |beam.io.WriteToText('/content/Data/Target/IN_US_Branch_employee_processed')\n",
        ")\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJy2TUnBNkyR",
        "outputId": "7df48628-643d-4c91-8f5f-6ecc586e8f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n",
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/Target/IN_US_Branch_employee_processed-00000-of-00001'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyoIqb7nQAFd",
        "outputId": "40c2a747-82ac-479e-f764-d5fa7ade7a1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7fc41eeaafb0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from a file and do required transformations on this file and write data into a file,without using lanbda funcions or by using Normal functions\n",
        "#Labeling[We can able to understand what is the meaning of each and every line]\n",
        "#while adding labeling each and every labeling should be unique\n",
        "#How to create multiple pcollections as per our requirements\n",
        "#How o link one pcollection with other pcollection[Branching]\n",
        "#How to perform Branching by using multiple transformation[Flatten]\n",
        "#combining\n",
        "import apache_beam as beam\n",
        "\n",
        "#Syntax for Composite Transformation\n",
        "class Transform(beam.PTransform):  #Transform name we can able to change\n",
        "  def expand(self,input_coll):  #input_coll we can change\n",
        "    coll=(   #coll we can change\n",
        "        input_coll\n",
        "        |'Adding one for each column' >> beam.Map(lambda record:(record[7],1))\n",
        "        |'Grouping and summing operations' >> beam.CombinePerKey(sum)\n",
        "    )\n",
        "    return coll\n",
        "\n",
        "def Split(record):\n",
        "  return record.split(',')\n",
        "\n",
        "def FilterUS(record):\n",
        "  return record[8]=='US'\n",
        "\n",
        "def FilterIN(record):\n",
        "  return record[8]=='IN'\n",
        "\n",
        "def addingOne(record):\n",
        "  return (record[7],1)\n",
        "\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "source_pcollection=(\n",
        "    p1\n",
        "    |'Read data from text file' >> beam.io.ReadFromText('/content/Data/Source/employee_3.txt')\n",
        "    |'Split based on comma' >> beam.Map(Split)\n",
        ")\n",
        "\n",
        "US_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|'appending one for each department id' >> beam.Map(addingOne)\n",
        "    #|'Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Composite Transformation1' >> Transform()\n",
        "   #|'Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/US_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "IN_Pcollection=(\n",
        "    source_pcollection\n",
        "    |'IN Filter based on Country' >> beam.Filter(Filter)\n",
        "    #|'IN appending one for each department id' >> beam.Map(addingOne)\n",
        "    #|'IN Grouping and summing data' >> beam.CombinePerKey(sum)\n",
        "    |'Composite Transformation2' >> Transform()\n",
        "    #|'IN Writing data into a file' >> beam.io.WriteToText('/content/Data/Target/IN_Branch_employee_processed')\n",
        ")\n",
        "\n",
        "Output=(\n",
        "    (US_Pcollection,IN_Pcollection)\n",
        "    |beam.Flatten()\n",
        "    |beam.io.WriteToText('/content/Data/Target/IN_US_Composite_Branch_employee_processed')\n",
        ")\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ZRRFY4VTA2",
        "outputId": "8f7fc5ec-4442-4b43-ee96-652ef06f62de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n",
            "('90', 2)\n",
            "('60', 3)\n",
            "('100', 4)\n",
            "('30', 4)\n",
            "('50', 23)\n",
            "('80', 22)\n",
            "('null', 1)\n",
            "('10', 1)\n",
            "('20', 2)\n",
            "('40', 1)\n",
            "('70', 1)\n",
            "('110', 2)\n"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/Target/IN_US_Composite_Branch_employee_processed-00000-of-00001'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpMDyQEsUrbL",
        "outputId": "3545196e-a311-467b-e248-5e47c18e9a96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7b46ea173040>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from CSV file and do filter operations and write data into csv file\n",
        "\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "def parse(row):\n",
        "  eid,ename,sal,did=row.split(',')\n",
        "  return{\n",
        "      'eid':eid.strip(),\n",
        "      'ename':ename.strip(),\n",
        "      'sal':sal.strip(),\n",
        "      'did':did.strip()\n",
        "  }\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |'Read data from CSV' >> beam.io.ReadFromText('/content/Data/source/Emp.csv',skip_header_lines=1)\n",
        "    |'Parse' >> beam.Map(parse)\n",
        "    |'Filter' >> beam.Filter(lambda row:row['did']=='10')\n",
        "    |'Write data into CSV' >> beam.io.WriteToText('/content/Data/target/output',file_name_suffix='.csv',header='eid,ename,sal,did')\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK3c_gwWa6Qu",
        "outputId": "c1998d25-85bd-4f54-ead2-90958977d39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eid,ename,sal,did\n",
            "{'eid': '1', 'ename': 'raja', 'sal': '200', 'did': '10'}\n",
            "{'eid': '3', 'ename': 'ted', 'sal': '400', 'did': '10'}\n"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/target/output-00000-of-00001.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6yq_P0LesaG",
        "outputId": "e334e135-01a9-419e-f644-ba61018385f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7b46e9fe6b30>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read data from CSV file and do filter operations and write data into avro file\n",
        "\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "avro_schema={\n",
        "    'fields':[\n",
        "        {'name':'eid','type':'string'},\n",
        "        {'name':'ename','type':'string'},\n",
        "        {'name':'sal','type':'string'},\n",
        "        {'name':'did','type':'string'}\n",
        "    ],\n",
        "    'name':'Employee',\n",
        "    'type':'record'\n",
        "}\n",
        "\n",
        "\n",
        "def parse(row):\n",
        "  eid,ename,sal,did=row.split(',')\n",
        "  return{\n",
        "      'eid':eid.strip(),\n",
        "      'ename':ename.strip(),\n",
        "      'sal':sal.strip(),\n",
        "      'did':did.strip()\n",
        "  }\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |'Read data from CSV' >> beam.io.ReadFromText('/content/Data/source/Emp.csv',skip_header_lines=1)\n",
        "    |'Parse' >> beam.Map(parse)\n",
        "    |'Filter' >> beam.Filter(lambda row:row['did']=='10')\n",
        "    |'Write data into CSV' >> beam.io.WriteToAvro('/content/Data/target/output.avro',schema=avro_schema,file_name_suffix='.avro')\n",
        ")\n",
        "\n",
        "p1.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p14MiyDqiqTI",
        "outputId": "e97031fe-49a8-4dc9-cef5-f9fdacb1ffb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obj\u0001\u0004\u0014avro.codec\u000edeflate\u0016avro.schema�\u0003{\"fields\": [{\"name\": \"eid\", \"type\": \"string\"}, {\"name\": \"ename\", \"type\": \"string\"}, {\"name\": \"sal\", \"type\": \"string\"}, {\"name\": \"did\", \"type\": \"string\"}], \"name\": \"Employee\", \"type\": \"record\"}\u0000\u0018�_X\r��@�l�����3\u00048c2�(J�Jd320`14`2f+IMa3\u0001s\u0000L�\u0005\u0018�_X\r��@�l�����3"
          ]
        }
      ],
      "source": [
        "!cat '/content/Data/target/output.avro-00000-of-00001.avro'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-J1VKeCi6_g",
        "outputId": "d075cad1-dfef-4a3e-e968-55910e7d7504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eid': '1', 'ename': 'raja', 'sal': '200', 'did': '10'}\n",
            "{'eid': '3', 'ename': 'ted', 'sal': '400', 'did': '10'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7b46ea422920>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ToRead data from Avro\n",
        "\n",
        "import apache_beam as beam\n",
        "p1=beam.Pipeline()\n",
        "\n",
        "lines=(\n",
        "    p1\n",
        "    |'Read data from Avro'  >> beam.io.ReadFromAvro('/content/Data/target/output.avro-00000-of-00001.avro')\n",
        "    |'Print' >> beam.Map(print)\n",
        ")\n",
        "\n",
        "p1.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "0FOWCdEi3PPz",
        "outputId": "c8435273-bbd0-41e8-8835-767de041636d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read data from Transcation file and Publishing in Topic\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Data being published to Pub/Sub must be sent as a bytestring.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8d193bb04073>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Read data from Transcation file and Publishing in Topic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpublisher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpubsub_topic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/pubsub_v1/publisher/client.py\u001b[0m in \u001b[0;36mpublish\u001b[0;34m(self, topic, data, ordering_key, retry, timeout, **attrs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;31m# If it is literally anything else, complain loudly about it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    342\u001b[0m                 \u001b[0;34m\"Data being published to Pub/Sub must be sent as a bytestring.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             )\n",
            "\u001b[0;31mTypeError\u001b[0m: Data being published to Pub/Sub must be sent as a bytestring."
          ]
        }
      ],
      "source": [
        "#To publish messages\n",
        "\n",
        "import csv\n",
        "import time\n",
        "from google.cloud import pubsub_v1\n",
        "import os\n",
        "\n",
        "project='rajaproject9848'\n",
        "pubsub_topic='projects/rajaproject9848/topics/retaildataT'\n",
        "service_account_key='/content/Data/source/rajaproject9848-74c61b0cebac.json'\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=service_account_key\n",
        "\n",
        "input_file='/content/Data/source/transaction1.csv'\n",
        "\n",
        "publisher=pubsub_v1.PublisherClient()\n",
        "with open(input_file,'r') as file:\n",
        "  for row in file:\n",
        "    print('Read data from Transcation file and Publishing in Topic')\n",
        "    publisher.publish(pubsub_topic,row)\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoSrQL7h-unu",
        "outputId": "b0146c78-a89a-43f3-eeb0-aa4c2f599aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-pubsub in /usr/local/lib/python3.10/dist-packages (2.23.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (2.19.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (3.20.3)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (0.13.1)\n",
            "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub) (1.48.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-pubsub) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-pubsub) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-pubsub) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-pubsub) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-pubsub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install google-cloud-pubsub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDVj5NDt-Fg3",
        "outputId": "1a7d50c7-a5a0-43d3-b3ec-d7b2edbf8161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read data from Transcation file and Publishing in Topic\n",
            "Read data from Transcation file and Publishing in Topic\n",
            "Read data from Transcation file and Publishing in Topic\n"
          ]
        }
      ],
      "source": [
        "#To publish messages\n",
        "\n",
        "import csv\n",
        "import time\n",
        "from google.cloud import pubsub_v1\n",
        "import os\n",
        "\n",
        "project='rajaproject9848'\n",
        "pubsub_topic='projects/rajaproject9848/topics/retaildataT'\n",
        "service_account_key='/content/Data/source/rajaproject9848-74c61b0cebac.json'\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=service_account_key\n",
        "\n",
        "input_file='/content/Data/source/transaction1.csv'\n",
        "\n",
        "publisher=pubsub_v1.PublisherClient()\n",
        "with open(input_file,'r') as file:\n",
        "  for row in file:\n",
        "    print('Read data from Transcation file and Publishing in Topic')\n",
        "    publisher.publish(pubsub_topic,row.encode('utf-8'))\n",
        "    time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "f_YtNSLf_nKh"
      },
      "outputs": [],
      "source": [
        "#Reading data from subscription and Filtering operations and writing the data to your topics and subscription\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import StandardOptions # Import StandardOptions\n",
        "import time\n",
        "from apache_beam import window\n",
        "\n",
        "serviceAccount='/content/Data/source/rajaproject9848-74c61b0cebac.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=serviceAccount\n",
        "\n",
        "input_subscription='projects/rajaproject9848/subscriptions/retaildataS'\n",
        "delivered_product_topic='projects/rajaproject9848/topics/retaildataDeliveryT'\n",
        "delivery_subscription='projects/rajaproject9848/subscriptions/retaildataDelveryS'\n",
        "\n",
        "options=PipelineOptions()\n",
        "options.view_as(StandardOptions).streaming=True\n",
        "\n",
        "p=beam.Pipeline(options=options)\n",
        "\n",
        "\n",
        "pubsub_pipeline=(\n",
        "    p\n",
        "    |'Read transcation data from PubSub subscription' >> beam.io.ReadFromPubSub(subscription=input_subscription)\n",
        "    |'Split the records by comma' >> beam.Map(lambda row:row.decode('utf-8').split(','))\n",
        "    |'Filter products with delivered category' >> beam.Filter(lambda row:(\"delivered\" in row[2]))\n",
        "    |'Converting to byte string' >> beam.Map(lambda row:(\".join(row).encode(utf-8)\"))\n",
        "    |'Publish to delivery topic' >> beam.io.WriteToPubSub(delivered_product_topic)\n",
        ")\n",
        "result=p.run()\n",
        "#result.wait_until_finish()\n",
        "\n",
        "#Displaying data from Delivery Subscription\n",
        "\n",
        "subscriber=pubsub_v1.SubscriberClient()\n",
        "\n",
        "def callback(message):\n",
        "  print(('Received Message:{}'.format(message)))\n",
        "  message.ack()\n",
        "\n",
        "\n",
        "subscriber.subscribe(delivery_subscription,callback=callback)\n",
        "\n",
        "while True:\n",
        "  time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6K48wg6Fooo",
        "outputId": "4dcf15f5-5888-4086-a73b-7a1ac391f892"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-ec01f285-68ec-48b7-85ca-c700dbd8687e.json']\n",
            "WARNING:apache_beam.runners.direct.direct_runner:The DirectPipelineResult is being garbage-collected while the DirectRunner is still running the corresponding pipeline. This may lead to incomplete execution of the pipeline if the main thread exits before pipeline completion. Consider using result.wait_until_finish() to wait for completion of pipeline execution.\n"
          ]
        }
      ],
      "source": [
        "#Reading data from subscription and Filtering operations and writing the data to your topics and subscription\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.options.pipeline_options import StandardOptions # Import StandardOptions\n",
        "import time\n",
        "from apache_beam import window\n",
        "\n",
        "serviceAccount='/content/Data/source/rajaproject9848-74c61b0cebac.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=serviceAccount\n",
        "\n",
        "input_subscription='projects/rajaproject9848/subscriptions/retaildataS'\n",
        "delivered_product_topic='projects/rajaproject9848/topics/retaildataDeliveryT'\n",
        "delivery_subscription='projects/rajaproject9848/subscriptions/retaildataDelveryS'\n",
        "\n",
        "options=PipelineOptions()\n",
        "options.view_as(StandardOptions).streaming=True\n",
        "\n",
        "p=beam.Pipeline(options=options)\n",
        "\n",
        "\n",
        "pubsub_pipeline=(\n",
        "    p\n",
        "    |'Read transcation data from PubSub subscription' >> beam.io.ReadFromPubSub(subscription=input_subscription)\n",
        "    |'Split the records by comma' >> beam.Map(lambda row:row.decode('utf-8').split(','))\n",
        "    |'Filter products with delivered category' >> beam.Filter(lambda row:(\"delivered\" in row[2]))\n",
        "    |'Converting to byte string' >> beam.Map(lambda row:(\".join(row).encode(utf-8)\"))\n",
        "    |'Publish to delivery topic' >> beam.io.WriteToPubSub(delivered_product_topic)\n",
        ")\n",
        "result=p.run()\n",
        "#result.wait_until_finish()\n",
        "\n",
        "#Displaying data from Delivery Subscription\n",
        "\n",
        "subscriber=pubsub_v1.SubscriberClient()\n",
        "\n",
        "def callback(message):\n",
        "  print(('Received Message:{}'.format(message)))\n",
        "  message.ack()\n",
        "\n",
        "\n",
        "subscriber.subscribe(delivery_subscription,callback=callback)\n",
        "\n",
        "while True:\n",
        "  time.sleep(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrrzEZCQFHPWcfMQDUlb75",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}